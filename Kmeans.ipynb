{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status: 0 / 147/r    Status: 1 / 147/r    Status: 2 / 147/r    Status: 3 / 147/r    Status: 4 / 147/r    Status: 5 / 147/r    Status: 6 / 147/r    Status: 7 / 147/r    Status: 8 / 147/r    Status: 9 / 147/r    Status: 10 / 147/r    Status: 11 / 147/r    Status: 12 / 147/r    Status: 13 / 147/r    Status: 14 / 147/r    Status: 15 / 147/r    Status: 16 / 147/r    Status: 17 / 147/r    Status: 18 / 147/r    Status: 19 / 147/r    Status: 20 / 147/r    Status: 21 / 147/r    Status: 22 / 147/r    Status: 23 / 147/r    Status: 24 / 147/r    Status: 25 / 147/r    Status: 26 / 147/r    Status: 27 / 147/r    Status: 28 / 147/r    Status: 29 / 147/r    Status: 30 / 147/r    Status: 31 / 147/r    Status: 32 / 147/r    Status: 33 / 147/r    Status: 34 / 147/r    Status: 35 / 147/r    Status: 36 / 147/r    Status: 37 / 147/r    Status: 38 / 147/r    Status: 39 / 147/r    Status: 40 / 147/r    Status: 41 / 147/r    Status: 42 / 147/r    Status: 43 / 147/r    Status: 44 / 147/r    Status: 45 / 147/r    Status: 46 / 147/r    Status: 47 / 147/r    Status: 48 / 147/r    Status: 49 / 147/r    Status: 50 / 147/r    Status: 51 / 147/r    Status: 52 / 147/r    Status: 53 / 147/r    Status: 54 / 147/r    Status: 55 / 147/r    Status: 56 / 147/r    Status: 57 / 147/r    Status: 58 / 147/r    Status: 59 / 147/r    Status: 60 / 147/r    Status: 61 / 147/r    Status: 62 / 147/r    Status: 63 / 147/r    Status: 64 / 147/r    Status: 65 / 147/r    Status: 66 / 147/r    Status: 67 / 147/r    Status: 68 / 147/r    Status: 69 / 147/r    Status: 70 / 147/r    Status: 71 / 147/r    Status: 72 / 147/r    Status: 73 / 147/r    Status: 74 / 147/r    Status: 75 / 147/r    Status: 76 / 147/r    Status: 77 / 147/r    Status: 78 / 147/r    Status: 79 / 147/r    Status: 80 / 147/r    Status: 81 / 147/r    Status: 82 / 147/r    Status: 83 / 147/r    Status: 84 / 147/r    Status: 85 / 147/r    Status: 86 / 147/r    Status: 87 / 147/r    Status: 88 / 147/r    Status: 89 / 147/r    Status: 90 / 147/r    Status: 91 / 147/r    Status: 92 / 147/r    Status: 93 / 147/r    Status: 94 / 147/r    Status: 95 / 147/r    Status: 96 / 147/r    Status: 97 / 147/r    Status: 98 / 147/r    Status: 99 / 147/r    Status: 100 / 147/r    Status: 101 / 147/r    Status: 102 / 147/r    Status: 103 / 147/r    Status: 104 / 147/r    Status: 105 / 147/r    Status: 106 / 147/r    Status: 107 / 147/r    Status: 108 / 147/r    Status: 109 / 147/r    Status: 110 / 147/r    Status: 111 / 147/r    Status: 112 / 147/r    Status: 113 / 147/r    Status: 114 / 147/r    Status: 115 / 147/r    Status: 116 / 147/r    Status: 117 / 147/r    Status: 118 / 147/r    Status: 119 / 147/r    Status: 120 / 147/r    Status: 121 / 147/r    Status: 122 / 147/r    Status: 123 / 147/r    Status: 124 / 147/r    Status: 125 / 147/r    Status: 126 / 147/r    Status: 127 / 147/r    Status: 128 / 147/r    Status: 129 / 147/r    Status: 130 / 147/r    Status: 131 / 147/r    Status: 132 / 147/r    Status: 133 / 147/r    Status: 134 / 147/r    Status: 135 / 147/r    Status: 136 / 147/r    Status: 137 / 147/r    Status: 138 / 147/r    Status: 139 / 147/r    Status: 140 / 147/r    Status: 141 / 147/r    Status: 142 / 147/r    Status: 143 / 147/r    Status: 144 / 147/r    Status: 145 / 147/r    Status: 146 / 147/r/n\n",
      "    Copy: 0 / 147/r    Copy: 1 / 147/r    Copy: 2 / 147/r    Copy: 3 / 147/r    Copy: 4 / 147/r    Copy: 5 / 147/r    Copy: 6 / 147/r    Copy: 7 / 147/r    Copy: 8 / 147/r    Copy: 9 / 147/r    Copy: 10 / 147/r    Copy: 11 / 147/r    Copy: 12 / 147/r    Copy: 13 / 147/r    Copy: 14 / 147/r    Copy: 15 / 147/r    Copy: 16 / 147/r    Copy: 17 / 147/r    Copy: 18 / 147/r    Copy: 19 / 147/r    Copy: 20 / 147/r    Copy: 21 / 147/r    Copy: 22 / 147/r    Copy: 23 / 147/r    Copy: 24 / 147/r    Copy: 25 / 147/r    Copy: 26 / 147/r    Copy: 27 / 147/r    Copy: 28 / 147/r    Copy: 29 / 147/r    Copy: 30 / 147/r    Copy: 31 / 147/r    Copy: 32 / 147/r    Copy: 33 / 147/r    Copy: 34 / 147/r    Copy: 35 / 147/r    Copy: 36 / 147/r    Copy: 37 / 147/r    Copy: 38 / 147/r    Copy: 39 / 147/r    Copy: 40 / 147/r    Copy: 41 / 147/r    Copy: 42 / 147/r    Copy: 43 / 147/r    Copy: 44 / 147/r    Copy: 45 / 147/r    Copy: 46 / 147/r    Copy: 47 / 147/r    Copy: 48 / 147/r    Copy: 49 / 147/r    Copy: 50 / 147/r    Copy: 51 / 147/r    Copy: 52 / 147/r    Copy: 53 / 147/r    Copy: 54 / 147/r    Copy: 55 / 147/r    Copy: 56 / 147/r    Copy: 57 / 147/r    Copy: 58 / 147/r    Copy: 59 / 147/r    Copy: 60 / 147/r    Copy: 61 / 147/r    Copy: 62 / 147/r    Copy: 63 / 147/r    Copy: 64 / 147/r    Copy: 65 / 147/r    Copy: 66 / 147/r    Copy: 67 / 147/r    Copy: 68 / 147/r    Copy: 69 / 147/r    Copy: 70 / 147/r    Copy: 71 / 147/r    Copy: 72 / 147/r    Copy: 73 / 147/r    Copy: 74 / 147/r    Copy: 75 / 147/r    Copy: 76 / 147/r    Copy: 77 / 147/r    Copy: 78 / 147/r    Copy: 79 / 147/r    Copy: 80 / 147/r    Copy: 81 / 147/r    Copy: 82 / 147/r    Copy: 83 / 147/r    Copy: 84 / 147/r    Copy: 85 / 147/r    Copy: 86 / 147/r    Copy: 87 / 147/r    Copy: 88 / 147/r    Copy: 89 / 147/r    Copy: 90 / 147/r    Copy: 91 / 147/r    Copy: 92 / 147/r    Copy: 93 / 147/r    Copy: 94 / 147/r    Copy: 95 / 147/r    Copy: 96 / 147/r    Copy: 97 / 147/r    Copy: 98 / 147/r    Copy: 99 / 147/r    Copy: 100 / 147/r    Copy: 101 / 147/r    Copy: 102 / 147/r    Copy: 103 / 147/r    Copy: 104 / 147/r    Copy: 105 / 147/r    Copy: 106 / 147/r    Copy: 107 / 147/r    Copy: 108 / 147/r    Copy: 109 / 147/r    Copy: 110 / 147/r    Copy: 111 / 147/r    Copy: 112 / 147/r    Copy: 113 / 147/r    Copy: 114 / 147/r    Copy: 115 / 147/r    Copy: 116 / 147/r    Copy: 117 / 147/r    Copy: 118 / 147/r    Copy: 119 / 147/r    Copy: 120 / 147/r    Copy: 121 / 147/r    Copy: 122 / 147/r    Copy: 123 / 147/r    Copy: 124 / 147/r    Copy: 125 / 147/r    Copy: 126 / 147/r    Copy: 127 / 147/r    Copy: 128 / 147/r    Copy: 129 / 147/r    Copy: 130 / 147/r    Copy: 131 / 147/r    Copy: 132 / 147/r    Copy: 133 / 147/r    Copy: 134 / 147/r    Copy: 135 / 147/r    Copy: 136 / 147/r    Copy: 137 / 147/r    Copy: 138 / 147/r    Copy: 139 / 147/r    Copy: 140 / 147/r    Copy: 141 / 147/r    Copy: 142 / 147/r    Copy: 143 / 147/r    Copy: 144 / 147/r    Copy: 145 / 147/r    Copy: 146 / 147/r"
     ]
    }
   ],
   "source": [
    "#We have used VGG16 here, which is a pre trained CNN model in Keras, for feature identification purposes from the maps.\n",
    "#These arrays (features) are then used by the k-means method for forming clusters. Help for this code has been taken from online articles related to this topic.\n",
    "#After clustering, a silhouette score is also checked (which ranges between -1 to +1), where a low score represnts poor clustering and higher represents good clustering.\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os, shutil, glob, os.path\n",
    "from PIL import Image as pil_image\n",
    "import tensorflow as tf\n",
    "image.LOAD_TRUNCATED_IMAGES = True \n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Variables\n",
    "imdir = 'C:/Users/rites/Desktop/JRF Work/VOCs/Paper work/Plots/maps'\n",
    "targetdir = \"C:/Users/rites/Desktop/JRF Work/VOCs/Paper work/Plots/clusters/\"\n",
    "number_clusters = 4\n",
    "\n",
    "# Loop over files and get features\n",
    "filelist = glob.glob(os.path.join(imdir, '*.gif'))\n",
    "filelist.sort()\n",
    "featurelist = []\n",
    "for i, imagepath in enumerate(filelist):\n",
    "    print(\"    Status: %s / %s\" %(i, len(filelist)), end=\"/r\")\n",
    "    img = image.load_img(imagepath, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    features = np.array(model.predict(img_data))\n",
    "    featurelist.append(features.flatten())\n",
    "\n",
    "# Clustering\n",
    "kmeans = KMeans(n_clusters=number_clusters, random_state=0).fit(np.array(featurelist))\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "metrics.silhouette_score(np.array(featurelist), kmeans.labels_, metric='euclidean')\n",
    "\n",
    "# Copy images renamed by cluster \n",
    "# Check if target dir exists\n",
    "try:\n",
    "    os.makedirs(targetdir)\n",
    "except OSError:\n",
    "    pass\n",
    "# Copy with cluster name\n",
    "print(\"/n\")\n",
    "for i, m in enumerate(kmeans.labels_):\n",
    "    print(\"    Copy: %s / %s\" %(i, len(kmeans.labels_)), end=\"/r\")\n",
    "    shutil.copy(filelist[i], targetdir + str(m) + \"_\" + str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059339408"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.silhouette_score(np.array(featurelist), kmeans.labels_, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
